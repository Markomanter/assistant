# llm.py

import httpx
import config
from db import save_turn
from translate import translate as mt_translate
from web_tools import web_search, format_results_for_llm
import json




# –ú–æ–¥–µ–ª—å –¥–ª—è "—Å–æ—Ä—Ç—É–≤–∞–ª—å–Ω–∏–∫–∞" / router-–∞ (–º–æ–∂–µ –±—É—Ç–∏ –ª–µ–≥—à–∞ –∑–∞ –æ—Å–Ω–æ–≤–Ω—É)
ROUTER_MODEL = getattr(config, "OLLAMA_ROUTER_MODEL", config.OLLAMA_MODEL)

OLLAMA_GENERATE_URL = config.OLLAMA_BASE_URL.rstrip("/") + "/api/generate"




def _split_think_and_answer(text: str) -> tuple[str, str]:
    """
    –†–æ–∑–¥—ñ–ª—è—î —Å–∏—Ä–∏–π —Ç–µ–∫—Å—Ç –º–æ–¥–µ–ª—ñ –Ω–∞:
    - think_text: —Ç–µ, —â–æ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ <think>...</think> (—è–∫—â–æ —î)
    - answer: —Ç–µ, —â–æ –ø—ñ—Å–ª—è </think> (—Ç–µ, —â–æ —Ç—Ä–µ–±–∞ –ø–æ–∫–∞–∑—É–≤–∞—Ç–∏/–æ–∑–≤—É—á—É–≤–∞—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É)
    """
    if not text:
        return "", ""

    raw = text.strip()
    think = ""
    answer = raw

    open_tag = "<think>"
    close_tag = "</think>"

    if close_tag in raw:
        # —à—É–∫–∞—î–º–æ –º–µ–∂—ñ think-–±–ª–æ–∫—É
        start = raw.find(open_tag)
        end = raw.rfind(close_tag)

        if start != -1 and end > start:
            think = raw[start + len(open_tag):end].strip()
        else:
            # —è–∫—â–æ <think> –Ω–µ–º–∞—î, –∞–ª–µ —î </think> ‚Äî –±–µ—Ä–µ–º–æ –≤—Å–µ –ø–µ—Ä–µ–¥ </think>
            think = raw[:end].strip()

        answer = raw[end + len(close_tag):].strip()

    # –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –º–æ–∂–ª–∏–≤–∏–π ```...``` –Ω–∞–≤–∫–æ–ª–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    if answer.startswith("```"):
        parts = answer.split("```")
        if len(parts) >= 3:
            answer = parts[-1].strip()

    return think, answer


def _generate_ollama(prompt: str, model: str | None = None) -> str:
    """
    –í–∏–∫–ª–∏–∫ /api/generate –¥–æ Ollama, –ø–æ–≤–µ—Ä—Ç–∞—î –°–ò–†–ò–ô —Ç–µ–∫—Å—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (–º–æ–∂–µ –º—ñ—Å—Ç–∏—Ç–∏ <think>).
    """
    if model is None:
        model = config.OLLAMA_MODEL

    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False,
        # –∑–∞ –±–∞–∂–∞–Ω–Ω—è–º –º–æ–∂–Ω–∞ –∑–∞—Ñ—ñ–∫—Å—É–≤–∞—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç:
        # "options": {"num_ctx": 2048},
    }

    print("ü§ñ –ó–∞–ø–∏—Ç—É—é –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Ollama (/api/generate)...")

    with httpx.Client(timeout=120.0) as client:
        resp = client.post(OLLAMA_GENERATE_URL, json=payload)
        resp.raise_for_status()
        data = resp.json()

    raw = (data.get("response") or "").strip()
    return raw


def translate_text(text: str, src: str, dst: str) -> str:
    """
    –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î text –∑ –º–æ–≤–∏ src –≤ –º–æ–≤—É dst, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏
    –æ–∫—Ä–µ–º—É –ª–µ–≥–∫—É –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–∫–ª–∞–¥—É (–Ω–µ Ollama).
    """
    return mt_translate(text, src=src, dst=dst)



def ask_ollama(
    user_text: str,
    user_lang: str | None = None,
    web_context: str | None = None,
) -> str:
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞.

    –Ø–∫—â–æ web_context –Ω–µ None ‚Äî –≤—ñ–Ω –±—É–¥–µ –¥–æ–¥–∞–Ω–∏–π –¥–æ –ø—Ä–æ–º–ø—Ç—É —è–∫
    –±–ª–æ–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–µ–±-–ø–æ—à—É–∫—É, –∞–ª–µ:
    - user_text –¥–ª—è –ë–î –Ω–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è,
    - –ø–µ—Ä–µ–∫–ª–∞–¥ –ø—Ä–∞—Ü—é—î —Ç—ñ–ª—å–∫–∏ –ø–æ–≤–µ—Ä—Ö user_text, web_context –Ω–µ –ø–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ.
    """
    lang = (user_lang or "unknown").lower()
    is_uk = lang.startswith("uk")

    # 1. –ì–æ—Ç—É—î–º–æ —Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–¥–µ–ª—ñ (–∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é)
    user_text_en = None
    model_input = user_text

    if is_uk:
        print("üîÅ –ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–ø–∏—Ç—É UK ‚Üí EN –¥–ª—è –º–æ–¥–µ–ª—ñ...")
        user_text_en = translate_text(user_text, src="uk", dst="en")
        print(f"üîÅ UK ‚Üí EN: {user_text_en!r}")
        model_input = user_text_en

    # 2. –û—Å–Ω–æ–≤–Ω–∏–π system-prompt: –º–æ–¥–µ–ª—å –¥—É–º–∞—î —ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –ê–ù–ì–õ–Ü–ô–°–¨–ö–û–Æ
    web_block = ""
    if web_context:
        web_block = (
            "\n\nHere are some web search results that may be relevant:\n"
            f"{web_context}\n"
            "When answering, rely primarily on these results if they are relevant,\n"
            "and say if something is still uncertain.\n"
        )

    system_prompt = (
        "You are a helpful AI assistant.\n"
        "- You ALWAYS think and answer in English.\n"
        f"- The original user language code was: {lang}.\n"
        "- You MAY use <think>...</think> for internal reasoning,\n"
        "  but the final answer for the user MUST be written AFTER the </think> tag,\n"
        "  in clean English.\n"
        "- The final answer should be concise (1‚Äì3 sentences) unless the question requires more.\n\n"
        f"{web_block}\n"
        "User message (in English):\n"
        f"{model_input}\n\n"
        "Assistant:"
    )

    raw = _generate_ollama(system_prompt)
    think, answer_en = _split_think_and_answer(raw)

    # ... (–¥–∞–ª—ñ –∑–∞–ª–∏—à–∞—î–º–æ —Ç–≤–æ—é –ª–æ–≥—ñ–∫—É THINK, –ø–µ—Ä–µ–∫–ª–∞–¥ EN‚ÜíUK, save_turn, return final_reply)

    # 3. THINK MODE –≤ –∫–æ–Ω—Å–æ–ª—ñ
    if think:
        print("\nüß† THINK MODE (–≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ —Ä–æ–∑–¥—É–º–∏ –º–æ–¥–µ–ª—ñ):")
        print(think)
        print("üß† END THINK\n")

    if not answer_en:
        answer_en = raw
        print("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —è–≤–Ω–æ–≥–æ </think>, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é –≤—Å—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å —è–∫ —Ñ—ñ–Ω–∞–ª—å–Ω—É (EN).")

    print(f"üí¨ –í—ñ–¥–ø–æ–≤—ñ–¥—å –º–æ–¥–µ–ª—ñ (EN, –¥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É): {answer_en!r}")

    # 4. –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –º–æ–≤–æ—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ + —Ä—è–¥–∫–∏ –¥–ª—è –ë–î
    final_reply = answer_en
    user_text_to_save = user_text
    assistant_reply_to_save = answer_en

    if is_uk:
        print("üîÅ –ü–µ—Ä–µ–∫–ª–∞–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ EN ‚Üí UK...")
        answer_uk = translate_text(answer_en, src="en", dst="uk")
        print(f"üîÅ EN ‚Üí UK: {answer_uk!r}")
        final_reply = answer_uk

        # —É –ë–î: —Å–ø–æ—á–∞—Ç–∫—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, –ø–æ—Ç—ñ–º –ø–µ—Ä–µ–∫–ª–∞–¥
        if user_text_en:
            user_text_to_save = f"{user_text}\n\n[EN]\n{user_text_en}"
        else:
            user_text_to_save = user_text

        assistant_reply_to_save = f"{answer_uk}\n\n[EN]\n{answer_en}"

    # 5. –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –±–∞–∑—É –¥–∞–Ω–∏—Ö
    try:
        save_turn(
            user_text=user_text_to_save,
            user_lang=lang,
            assistant_think=think,
            assistant_reply=assistant_reply_to_save,
        )
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ —Ä–æ–∑–º–æ–≤—É –≤ –ë–î: {e}")

    # 6. –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å (—ó—ó –ø–æ–±–∞—á–∏—à —É –∫–æ–Ω—Å–æ–ª—ñ –π –ø–æ—á—É—î—à —É TTS)
    return final_reply


def decide_need_web(user_text: str, user_lang: str | None) -> tuple[bool, str]:
    """
    –í–∏—Ä—ñ—à—É—î, —á–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω –≤–µ–±-–ø–æ—à—É–∫.
    –õ–æ–≥—ñ–∫–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –≤–∏–Ω–µ—Å–µ–Ω–∞ –≤ –æ–∫—Ä–µ–º—É –ª–µ–≥–∫—É router-–º–æ–¥–µ–ª—å (Qwen3:0.6b).
    """
    system_prompt = """
    You are a classifier that decides whether a web search is needed.

    Return STRICT JSON with keys:
    - "need_web": true or false
    - "search_query": string (may be empty if need_web is false)

    Use web search when the question is about:
    - current or recent events (news, politics, war, etc.),
    - current prices, availability, product lists,
    - weather right now or forecast,
    - live sports results, timetables, schedules,
    - anything that clearly depends on up-to-date external data.

    Do NOT request web search for:
    - general knowledge that does not change often,
    - programming questions,
    - math and logic,
    - advice that does not need exact current facts.

    Respond with JSON only. Do NOT add any extra text.
    """
    lang = (user_lang or "unknown").lower()
    prompt = f"{system_prompt}\n\nUser language: {lang}\nUser question:\n{user_text}"

    # –¢—É—Ç –º–∏ —è–≤–Ω–æ —é–∑–∞—î–º–æ ROUTER_MODEL (Qwen3:0.6b), –∞ –Ω–µ –æ—Å–Ω–æ–≤–Ω—É –º–æ–¥–µ–ª—å.
    raw = _generate_ollama(prompt, model=ROUTER_MODEL)

    try:
        data = json.loads(raw.strip())
        need_web = bool(data.get("need_web"))
        search_query = str(data.get("search_query") or "").strip()
        return need_web, search_query
    except Exception:
        # —è–∫—â–æ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–ª–∞ JSON ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–µ —Ä–æ–±–∏–º–æ –≤–µ–±
        print(f"‚ö†Ô∏è decide_need_web: –Ω–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ JSON: {raw!r}")
        return False, ""

def ask_ollama_smart(user_text: str, user_lang: str | None = None) -> str:
    """
    –û–±–≥–æ—Ä—Ç–∫–∞ –Ω–∞–¥ ask_ollama, —è–∫–∞:
    1) –≤–∏—Ä—ñ—à—É—î, —á–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω –≤–µ–±-–ø–æ—à—É–∫;
    2) —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω ‚Äî —Ä–æ–±–∏—Ç—å –ø–æ—à—É–∫ —ñ –¥–æ–¥–∞—î web_context —É –ø—Ä–æ–º–ø—Ç;
    3) —ñ–Ω–∞–∫—à–µ –ø—Ä–∞—Ü—é—î —è–∫ –∑–≤–∏—á–∞–π–Ω–∏–π ask_ollama.
    """
    need_web, search_query = decide_need_web(user_text, user_lang)

    if not need_web:
        print("üåê –í–µ–±-–ø–æ—à—É–∫ –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω, –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é –ª–æ–∫–∞–ª—å–Ω–æ.")
        return ask_ollama(user_text, user_lang)

    if not search_query:
        search_query = user_text

    print(f"üåê –†–æ–±–ª—é –≤–µ–±-–ø–æ—à—É–∫ –¥–ª—è –∑–∞–ø–∏—Ç—É: {search_query!r}")
    results = web_search(search_query, max_results=5)

    if not results:
        print("üåê –í–µ–±-–ø–æ—à—É–∫ –Ω—ñ—á–æ–≥–æ –Ω–µ –¥–∞–≤, –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é —è–∫ –∑–≤–∏—á–∞–π–Ω–æ (–±–µ–∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É).")
        return ask_ollama(user_text, user_lang)

    web_context = format_results_for_llm(results)

    return ask_ollama(user_text, user_lang, web_context=web_context)


def ask_ollama_with_web(user_text: str, user_lang: str | None) -> str:
    """
    –í–∞—Ä—ñ–∞–Ω—Ç –∑–∞–ø–∏—Ç—É –¥–æ LLM, —è–∫–∏–π —Å–ø–æ—á–∞—Ç–∫—É —Ä–æ–±–∏—Ç—å –≤–µ–±-–ø–æ—à—É–∫,
    –∞ –ø–æ—Ç—ñ–º –¥–∞—î –º–æ–¥–µ–ª—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.
    """

    lang = (user_lang or "unknown").lower()
    is_uk = lang.startswith("uk")

    # 1. –§–æ—Ä–º—É—î–º–æ –∑–∞–ø–∏—Ç –¥–ª—è –ø–æ—à—É–∫—É (–º–æ–∂–Ω–∞ –ø—Ä—è–º–æ —Ç–µ–∫—Å—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞)
    search_query = user_text.strip()

    print(f"üåê –†–æ–±–ª—é –≤–µ–±-–ø–æ—à—É–∫ –¥–ª—è –∑–∞–ø–∏—Ç—É: {search_query!r}")
    results = web_search(search_query, max_results=5)

    if not results:
        print("üåê –í–µ–±-–ø–æ—à—É–∫ –Ω—ñ—á–æ–≥–æ –Ω–µ –¥–∞–≤, –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é —è–∫ –∑–≤–∏—á–∞–π–Ω–æ (–±–µ–∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É).")
        # fallback ‚Äî –∑–≤–∏—á–∞–π–Ω–∏–π ask_ollama
        return ask_ollama(user_text, user_lang)

    web_context = format_results_for_llm(results)

    # 2. –ì–æ—Ç—É—î–º–æ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—é –¥–ª—è –º–æ–¥–µ–ª—ñ
    #    (—â–æ–± –≤–æ–Ω–∞ –æ–ø–∏—Ä–∞–ª–∞—Å—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É)
    target_lang_name = "English"  # –±–æ –º–æ–¥–µ–ª—å –¥—É–º–∞—î –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é

    prompt = f"""
    You are an AI assistant that answers using web search results.

    User question:
    \"\"\"{user_text}\"\"\"

    Web search results (may contain noise, but also the answer):
    \"\"\"{web_context}\"\"\"

    Your task:
    - Look through the web results and EXTRACT concrete factual information relevant to the question.
    - If the question is about current weather, you MUST try to extract:
    - current temperature,
    - feels-like temperature (if available),
    - weather condition (e.g. cloudy, rain),
    - wind and humidity (if mentioned).
    - Quote NUMERIC values exactly as they appear in the snippets.
    - If you cannot find specific numbers, clearly say: "I could not find exact current values, only general information."

    Answer in {target_lang_name}.
    Give a single, concise paragraph with the extracted data.
    """

    # 3. –í–∏–∫–ª–∏–∫–∞—î–º–æ ‚Äú—Å–∏—Ä—É‚Äù –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é —á–µ—Ä–µ–∑ Ollama
    #    (—É —Ç–µ–±–µ –≤–∂–µ —î –≤–Ω—É—Ç—Ä—ñ—à–Ω—è —Ñ—É–Ω–∫—Ü—ñ—è _generate_ollama)
    raw = _generate_ollama(prompt)

    # 4. –†–æ–∑–¥—ñ–ª—è—î–º–æ think / answer, —è–∫ —Ç–∏ –≤–∂–µ —Ä–æ–±–∏—à –≤ ask_ollama
    think, answer = _split_think_and_answer(raw)

    # –ú–æ–∂–Ω–∞ –ø—Ä–∏ –±–∞–∂–∞–Ω–Ω—ñ –∑–±–µ—Ä–µ–≥—Ç–∏ –≤ –ë–î –æ–∫—Ä–µ–º–æ, –∞–ª–µ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–≤–µ—Ä–Ω–µ–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    return answer.strip() or raw.strip()
